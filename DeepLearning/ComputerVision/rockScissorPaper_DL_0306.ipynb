{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3de4c3d-25b6-471d-b34c-029b4c88947c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "1.23.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ff0ba6-ea17-4e57-9f44-99df2a6c69f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print('import done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b42ad7-922a-4a37-9e42-c200825ab3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 images to be resized\n",
      "133 images resized\n",
      "scissor resize done\n"
     ]
    }
   ],
   "source": [
    "# resize images to be 28x28\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images = glob.glob(img_path + '/*.jpg')\n",
    "    \n",
    "    print(len(images), 'images to be resized')\n",
    "    \n",
    "    # resize to 28x28\n",
    "    target_size = (28,28)\n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        new_img = old_img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "        new_img.save(img, 'JPEG')\n",
    "        \n",
    "    print(len(images), 'images resized')\n",
    "    \n",
    "# 가위 전부 읽어들여서 리사이즈\n",
    "image_dir_path = '/Users/leegen/Downloads/RSP/scissor'\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print('scissor resize done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "870250ab-e368-439b-8c25-2b06e22d89a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 images to be resized\n",
      "107 images resized\n"
     ]
    }
   ],
   "source": [
    "# rock\n",
    "\n",
    "image_dir_path = '/Users/leegen/Downloads/RSP/rock'\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29ae1c32-797f-47a4-beba-a81379be4742",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 images to be resized\n",
      "118 images resized\n"
     ]
    }
   ],
   "source": [
    "# paper\n",
    "\n",
    "image_dir_path = '/Users/leegen/Downloads/RSP/paper'\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c0beca-47a6-4793-b41d-f33b79f25f03",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff09b6a-eccc-4b13-894f-ec159aecc2ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 358 입니다.\n",
      "x_train shape: (358, 28, 28, 3)\n",
      "y_train shape: (358,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=358):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32\n",
    "    ).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = \"/Users/leegen/Downloads/RSP\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe72cae-57c2-4a46-be48-4996ea27d86d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[1])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca1c0ab-7676-41c5-b709-7155746e6856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPT code for data augmentation\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# # Define an ImageDataGenerator for data augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#     width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "#     height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "#     shear_range=0.1,  # randomly shear images\n",
    "#     zoom_range=0.1,  # randomly zoom image\n",
    "#     horizontal_flip=True,  # randomly flip images\n",
    "#     fill_mode='nearest'  # fill in missing pixels after a transformation\n",
    "# )\n",
    "\n",
    "# # Compute quantities required for featurewise normalization\n",
    "# datagen.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d3f34c-eb02-4dae-9a21-0865f7d23361",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d37738-0420-4bb0-9915-cd4bfcfcd91b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358, 28, 28, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43576095-5ffe-4d25-8a2d-c30a459e2f94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.0033218 , 0.00350634, 0.00344483],\n",
       "        [0.00330642, 0.00349097, 0.00342945],\n",
       "        [0.00330642, 0.00347559, 0.00341407],\n",
       "        ...,\n",
       "        [0.00322953, 0.00330642, 0.00335256],\n",
       "        [0.00318339, 0.00326028, 0.00330642],\n",
       "        [0.00316801, 0.00322953, 0.00324491]],\n",
       "\n",
       "       [[0.00319877, 0.00336794, 0.00330642],\n",
       "        [0.00319877, 0.00336794, 0.00330642],\n",
       "        [0.00321415, 0.00335256, 0.00330642],\n",
       "        ...,\n",
       "        [0.00321415, 0.00329104, 0.00333718],\n",
       "        [0.00318339, 0.00324491, 0.00326028],\n",
       "        [0.00315263, 0.00321415, 0.00322953]],\n",
       "\n",
       "       [[0.00313725, 0.00327566, 0.00322953],\n",
       "        [0.00318339, 0.00327566, 0.00324491],\n",
       "        [0.00319877, 0.00329104, 0.00326028],\n",
       "        ...,\n",
       "        [0.00321415, 0.00329104, 0.00333718],\n",
       "        [0.00316801, 0.00322953, 0.00324491],\n",
       "        [0.00315263, 0.00321415, 0.00322953]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.00230681, 0.00224529, 0.00222991],\n",
       "        [0.00242983, 0.00235294, 0.00230681],\n",
       "        [0.00249135, 0.00241446, 0.00236832],\n",
       "        ...,\n",
       "        [0.00087659, 0.00143022, 0.00161476],\n",
       "        [0.00058439, 0.00110727, 0.00124567],\n",
       "        [0.00047674, 0.00098424, 0.00109189]],\n",
       "\n",
       "       [[0.00227605, 0.00219915, 0.00226067],\n",
       "        [0.0023837 , 0.00229143, 0.00229143],\n",
       "        [0.00249135, 0.00233756, 0.00230681],\n",
       "        ...,\n",
       "        [0.00053825, 0.00118416, 0.00143022],\n",
       "        [0.00041522, 0.00099962, 0.00116878],\n",
       "        [0.00039985, 0.00096886, 0.00110727]],\n",
       "\n",
       "       [[0.00222991, 0.00219915, 0.00227605],\n",
       "        [0.00235294, 0.00226067, 0.00226067],\n",
       "        [0.00246059, 0.00229143, 0.00222991],\n",
       "        ...,\n",
       "        [0.00032295, 0.00103037, 0.00127643],\n",
       "        [0.00033833, 0.00095348, 0.00110727],\n",
       "        [0.00036909, 0.00095348, 0.00109189]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize x_train\n",
    "\n",
    "x_train = x_train / 255\n",
    "print(y_train[0:5])\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec53341-7cde-427f-bcf9-1865419de95c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 16:31:58.673195: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-03-06 16:31:58.673278: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-03-06 16:31:58.673298: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-03-06 16:31:58.673431: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-06 16:31:58.673485: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 26, 26, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 11, 11, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 11, 11, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                51232     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,107\n",
      "Trainable params: 70,915\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 16:31:59.813948: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# model creation\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 아래의 하이퍼파라미터는 예시입니다. 높은 인식률을 얻기 위해 하이퍼파라미터를 수정해 보세요. \n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "model = keras.Sequential([\n",
    "            Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D(2,2),\n",
    "            Conv2D(64, (3,3), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            MaxPooling2D(2,2),\n",
    "            Flatten(),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(3, activation='softmax')  # Assuming you have 3 classes\n",
    "        ])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# model compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(x_train, y_train, epochs=n_train_epoch, validation_data=(x_val, y_val), verbose=1)\n",
    "\n",
    "\n",
    "# Continue with the previous plotting code...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191cc348-dd17-4a75-984e-f53cb3ce1f0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "---- 중간에 커널이 계속 꺼져서 lms 에서 돌렸습니다 ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596d150-ae3b-4edb-8c78-2fb7b36388a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37d7461f-5d2e-41e7-bb88-73d4810ae3b2",
   "metadata": {},
   "source": [
    "# 회고\n",
    "- 픽셀이 너무 깨지는 게 아닌가? 32*32 로 바꾸기\n",
    "- 육안으로도 구분이 안돼..\n",
    "- 리사이즈 한 채로 돌리면 깨져서 다시 압축 푸는것부터 다시 하기\n",
    "- dropout 추가, batch normalization 추가\n",
    "- 로컬에서 계속 커널이 꺼져서 중간에 lms 로 옮겨갔다\n",
    "- 왜 꺼지는지는 아직 잘 모르겠음\n",
    "- GPT 가 Data Augmentation 도 추천해줬는데 아직 못해봤음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7977be3d-7033-41ae-ae55-f6573442b981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
